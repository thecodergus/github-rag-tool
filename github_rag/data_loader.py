import os
import pandas as pd
from typing import List, Dict, Optional, Any
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader

from github_rag.github_client import GitHubClient


class GitHubDataLoader:
    """Carregador de dados do GitHub para vectoriza√ß√£o"""

    def __init__(self, github_client: GitHubClient):
        self.github_client = github_client
        self.issues_df = None
        self.code_files = None

    def load_data(
        self,
        content_types: List[str],
        limit_issues: Optional[int] = None,
        max_files: Optional[int] = None,
    ):
        """Carrega dados do GitHub com base nos tipos de conte√∫do especificados"""
        if "issue" in content_types:
            print("üîç Buscando issues...")
            self.issues_df = self.github_client.fetch_issues(limit=limit_issues)
            print(f"‚úÖ Encontrados {len(self.issues_df)} issues")

        if "code" in content_types:
            print("üîç Buscando arquivos de c√≥digo...")
            self.code_files = self.github_client.fetch_code_files(max_files=max_files)
            print(f"‚úÖ Encontrados {len(self.code_files)} arquivos de c√≥digo")

    def create_text_chunks(
        self, chunk_size: int = 1000, chunk_overlap: int = 200
    ) -> List[Dict[str, Any]]:
        """
        Cria chunks de texto a partir dos dados carregados, incluindo coment√°rios

        Args:
            chunk_size: Tamanho de cada chunk de texto
            chunk_overlap: Quantidade de sobreposi√ß√£o entre chunks

        Returns:
            Lista de documentos processados
        """
        documents = []
        text_splitter = CharacterTextSplitter(
            chunk_size=chunk_size, chunk_overlap=chunk_overlap
        )

        # Processar issues e PRs com seus coment√°rios
        if self.issues_df is not None and not self.issues_df.empty:
            for _, row in self.issues_df.iterrows():
                # Verificar se √© Issue ou PR
                item_type = row.get(
                    "type", "Issue"
                )  # Se n√£o existir, assume Issue por padr√£o
                item_number = row["number"]

                # Texto principal do item (Issue ou PR)
                if item_type == "Issue":
                    item_text = (
                        f"ISSUE #{item_number}: {row['title']}\n\n{row['body'] or ''}"
                    )
                    source_type = "issue"
                else:  # √â um PR
                    item_text = f"PULL REQUEST #{item_number}: {row['title']}\n\n{row['body'] or ''}"
                    # Adicionar informa√ß√µes espec√≠ficas de PR, se dispon√≠veis
                    if "additions" in row and "deletions" in row:
                        item_text += f"\nAdi√ß√µes: {row.get('additions', 0)}, Exclus√µes: {row.get('deletions', 0)}"
                    if "merged" in row:
                        item_text += f"\nStatus de Merge: {'Mesclado' if row.get('merged', False) else 'N√£o mesclado'}"
                    source_type = "pull_request"

                # Adicionar coment√°rios ao texto, se existirem
                comments = row.get("comments_data", [])
                if comments and len(comments) > 0:
                    item_text += "\n\n--- COMENT√ÅRIOS ---\n"
                    for i, comment in enumerate(comments, 1):
                        user = comment.get("user", "Usu√°rio")
                        body = comment.get("body", "")
                        created_at = comment.get("created_at", "")

                        item_text += (
                            f"\nCOMENT√ÅRIO #{i} por {user} em {created_at}:\n{body}\n"
                        )

                # Dividir em chunks
                chunks = text_splitter.split_text(item_text)

                for chunk in chunks:
                    documents.append(
                        {
                            "text": chunk,
                            "metadata": {
                                "source": source_type,
                                "number": item_number,
                                "url": row["html_url"],
                                "title": row["title"],
                                "has_comments": len(comments) > 0,
                                "type": item_type,  # Adicionar o tipo explicitamente nos metadados
                            },
                        }
                    )

        # Processar arquivos de c√≥digo (j√° com conte√∫do)
        if self.code_files:
            for file_info in self.code_files:
                content = file_info.get("content", "")
                if content:
                    chunks = text_splitter.split_text(content)

                    for chunk in chunks:
                        documents.append(
                            {
                                "text": chunk,
                                "metadata": {
                                    "source": "code",
                                    "filename": file_info["name"],
                                    "url": file_info["url"],
                                },
                            }
                        )

        return documents
