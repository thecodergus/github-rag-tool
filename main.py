# Instala√ß√£o
# pip install 'crewai[tools]' langchain langchain-openai langchain-community pandas python-dotenv chromadb faiss-cpu

import os
from dotenv import load_dotenv
from crewai import Agent, Task, Crew
from crewai_tools import GithubSearchTool
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.memory import ConversationBufferMemory, MongoDBChatMessageHistory
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
import pandas as pd
import json
import requests
from datetime import datetime

# Carregar vari√°veis de ambiente
load_dotenv()

# Configurar tokens
GITHUB_TOKEN = os.getenv("GITHUB_API_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL")
MONGODB_URI = os.getenv("MONGODB_URI")


class GitHubRagTool:
    def __init__(
        self,
        repo_url,
        content_types=["code", "issue"],
        custom_model=False,
        session_id=None,
    ):
        """
        Inicializa a ferramenta RAG para GitHub com capacidades de mem√≥ria.

        Args:
            repo_url: URL do reposit√≥rio GitHub (ex: 'https://github.com/exemplo/repo')
            content_types: Tipos de conte√∫do para busca ('code', 'repo', 'pr', 'issue')
            custom_model: Se True, usa modelos personalizados para embeddings
            session_id: ID da sess√£o para persist√™ncia de mem√≥ria
        """
        self.repo_url = repo_url
        self.content_types = content_types

        # Gerar ID de sess√£o se n√£o fornecido
        self.session_id = (
            session_id or f"github_session_{datetime.now().strftime('%Y%m%d%H%M%S')}"
        )

        # Configurar mem√≥ria de curto prazo (sess√£o atual)
        self.short_term_memory = ConversationBufferMemory(
            memory_key="chat_history", return_messages=True
        )

        # Configurar mem√≥ria de longo prazo (persistente)
        self.long_term_memory = MongoDBChatMessageHistory(
            connection_string=MONGODB_URI,
            session_id=self.session_id,
            database_name="github_agent_memory",
            collection_name="chat_history",
        )

        # Mesma configura√ß√£o do GithubSearchTool como no c√≥digo original
        if custom_model:
            self.tool = GithubSearchTool(
                github_repo=repo_url,
                content_types=content_types,
                gh_token=GITHUB_TOKEN,
                config=dict(
                    llm=dict(
                        provider="openai",
                        config=dict(
                            model=OPENAI_MODEL,
                            temperature=0.5,
                        ),
                    ),
                    embedder=dict(
                        provider="openai",
                        config=dict(
                            model=OPENAI_MODEL,
                        ),
                    ),
                ),
            )
        else:
            self.tool = GithubSearchTool(
                github_repo=repo_url,
                content_types=content_types,
                gh_token=GITHUB_TOKEN,
            )

        # Extrair informa√ß√µes do reposit√≥rio
        self.owner, self.repo_name = self.parse_repo_url(repo_url)

        # Inicializar a base RAG
        self.vector_db = None
        self.issues_df = None
        self.code_files = None

        # Inicialize a conversation chain e verifique se foi bem-sucedida
        self.conversation_chain = self.create_conversation_chain()

        # Inicializar o modelo de linguagem
        self.llm = ChatOpenAI(model=OPENAI_MODEL)

        self.retriever = self._setup_retriever()

        if self.conversation_chain is None:
            print("ERRO: Falha ao criar a cadeia de conversa√ß√£o!")
            # Log de informa√ß√µes para diagn√≥stico
            print(f"LLM inicializado: {self.llm is not None}")
            print(f"Retriever inicializado: {self.retriever is not None}")

    def setup_conversation_chain(self):
        """
        Configura a chain de conversa√ß√£o com a base de conhecimento e mem√≥ria
        """
        if not self.vector_db:
            print("Carregando dados do reposit√≥rio primeiro...")
            self.load_github_data()

        # Criar a chain de conversa√ß√£o
        self.conversation_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.vector_db.as_retriever(
                search_type="similarity", search_kwargs={"k": 5}
            ),
            memory=self.short_term_memory,
            return_source_documents=True,  # Importante para cita√ß√£o de fontes
            verbose=True,
        )

    def load_github_data(self, limit_issues=50, max_files=30):
        """
        Carrega os dados do GitHub e cria a base de conhecimento
        """
        print("Buscando issues...")
        self.issues_df = self.fetch_issues(limit=limit_issues)
        print(f"Encontrados {len(self.issues_df)} issues")

        print("Buscando arquivos de c√≥digo...")
        self.code_files = self.fetch_code_files(max_files=max_files)
        print(f"Encontrados {len(self.code_files)} arquivos de c√≥digo")

        # Criar base RAG
        print("Criando base RAG...")
        self.vector_db = self.create_rag_database(self.issues_df, self.code_files)

    def chat(self, user_input):
        if self.conversation_chain is None:
            # Tente criar a chain novamente
            self.conversation_chain = self.create_conversation_chain()

            # Se ainda for None, retorne uma mensagem de erro
            if self.conversation_chain is None:
                return {
                    "answer": "Erro interno: A cadeia de conversa√ß√£o n√£o foi inicializada corretamente. Verifique as configura√ß√µes e tente novamente.",
                    "sources": [],
                }

        # Continua com o c√≥digo normal
        result = self.conversation_chain({"question": user_input})
        return result

    def _extract_source_info(self, doc):
        """Extrai informa√ß√µes da fonte do documento"""
        if not doc.metadata:
            return None

        source_path = doc.metadata.get("source", "")

        if "issue_" in source_path:
            # √â um issue
            issue_number = source_path.split("issue_")[1].split(".")[0]
            issue_data = self.issues_df[
                self.issues_df["issue_number"] == int(issue_number)
            ]
            if not issue_data.empty:
                return {
                    "type": "issue",
                    "number": issue_number,
                    "title": issue_data.iloc[0]["title"],
                    "url": issue_data.iloc[0]["url"],
                }
        elif "code_" in source_path:
            # √â um arquivo de c√≥digo
            file_name = source_path.split("code_")[1].split(".")[0]
            for file in self.code_files:
                if file["name"].replace("/", "_") == file_name:
                    return {"type": "code", "path": file["path"], "url": file["url"]}

        return None

    def _format_response_with_citations(self, response, sources):
        """Formata a resposta com cita√ß√µes das fontes"""
        if not sources:
            return response

        formatted_response = f"{response}\n\n**Fontes:**\n"

        for i, source in enumerate(sources, 1):
            if source["type"] == "issue":
                formatted_response += f"{i}. Issue #{source['number']}: [{source['title']}]({source['url']})\n"
            elif source["type"] == "code":
                formatted_response += (
                    f"{i}. Arquivo: [{source['path']}]({source['url']})\n"
                )

        return formatted_response

    def parse_repo_url(self, url):
        """Extrai o propriet√°rio e o nome do reposit√≥rio da URL"""
        parts = url.strip("/").split("/")
        if "github.com" in parts:
            idx = parts.index("github.com")
            if len(parts) > idx + 2:
                return parts[idx + 1], parts[idx + 2]
        raise ValueError(f"URL de reposit√≥rio inv√°lida: {url}")

    def fetch_issues(self, state="all", limit=100):
        """
        Busca os issues do reposit√≥rio usando a API do GitHub

        Args:
            state: Estado dos issues ('open', 'closed', 'all')
            limit: N√∫mero m√°ximo de issues a serem buscados

        Returns:
            DataFrame com os issues
        """
        headers = {"Authorization": f"token {GITHUB_TOKEN}"}
        url = f"https://api.github.com/repos/{self.owner}/{self.repo_name}/issues"
        params = {"state": state, "per_page": 100}

        issues = []
        page = 1

        while len(issues) < limit:
            params["page"] = page
            response = requests.get(url, headers=headers, params=params)

            if response.status_code != 200:
                print(f"Erro ao buscar issues: {response.status_code}")
                break

            page_issues = response.json()
            if not page_issues:
                break

            issues.extend(page_issues)
            page += 1

        # Limitar ao n√∫mero desejado
        issues = issues[:limit]

        # Converter para DataFrame
        df = pd.DataFrame(
            [
                {
                    "issue_number": issue["number"],
                    "title": issue["title"],
                    "state": issue["state"],
                    "created_at": issue["created_at"],
                    "body": issue["body"] if issue["body"] else "",
                    "url": issue["html_url"],
                }
                for issue in issues
            ]
        )

        return df

    def fetch_code_files(self, path="", max_files=50):
        """
        Busca arquivos de c√≥digo no reposit√≥rio

        Args:
            path: Caminho dentro do reposit√≥rio para buscar (vazio = raiz)
            max_files: N√∫mero m√°ximo de arquivos a serem buscados

        Returns:
            Lista de informa√ß√µes de arquivos
        """
        headers = {"Authorization": f"token {GITHUB_TOKEN}"}
        url = f"https://api.github.com/repos/{self.owner}/{self.repo_name}/contents/{path}"

        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            print(f"Erro ao buscar arquivos: {response.status_code}")
            return []

        contents = response.json()
        files = []
        dirs = []

        for item in contents:
            if item["type"] == "file":
                files.append(
                    {
                        "name": item["name"],
                        "path": item["path"],
                        "url": item["html_url"],
                        "download_url": item["download_url"],
                    }
                )
            elif item["type"] == "dir":
                dirs.append(item["path"])

        # Recursivamente buscar em subdiret√≥rios se ainda n√£o atingimos o limite
        if len(files) < max_files and dirs:
            for dir_path in dirs[: min(len(dirs), (max_files - len(files)))]:
                files.extend(self.fetch_code_files(dir_path, max_files - len(files)))
                if len(files) >= max_files:
                    break

        return files[:max_files]

    def download_file_content(self, download_url):
        """Baixa o conte√∫do de um arquivo a partir da URL de download"""
        headers = {"Authorization": f"token {GITHUB_TOKEN}"}
        response = requests.get(download_url, headers=headers)
        if response.status_code == 200:
            return response.text
        return None

    def create_rag_database(self, issues_df, code_files):
        """
        Cria uma base de dados RAG a partir de issues e c√≥digo.

        Args:
            issues_df: DataFrame com issues
            code_files: Lista de arquivos de c√≥digo

        Returns:
            ChromaVectorStore: Base de dados vetorial
        """
        print("Criando base RAG...")

        # Garantir que o diret√≥rio existe
        os.makedirs("./github_rag_db", exist_ok=True)

        # Processar e salvar issues
        documents = []
        for i, issue in issues_df.iterrows():
            issue_path = f"./github_rag_db/issue_{issue['issue_number']}.txt"
            with open(issue_path, "w", encoding="utf-8") as f:
                f.write(f"Title: {issue['title']}\n")
                f.write(f"State: {issue['state']}\n")
                f.write(f"Created: {issue['created_at']}\n")
                f.write(f"Body:\n{issue['body']}\n")
                f.write(f"URL: {issue['url']}\n")

            # Use UTF-8 encoding when loading the file
            loader = TextLoader(issue_path, encoding="utf-8")
            documents.extend(loader.load())

        # Processar e salvar c√≥digo
        for file in code_files:
            # Baixar o conte√∫do do arquivo
            content = self.download_file_content(file["download_url"])

            # Se conseguiu baixar o conte√∫do
            if content:
                file_path = f"./github_rag_db/code_{file['name'].replace('/', '_')}.txt"
                print(file)
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(f"Path: {file['path']}\n")
                    f.write(f"URL: {file['url']}\n")
                    f.write(f"Content:\n{content}\n")

                # Use UTF-8 encoding when loading the file
                loader = TextLoader(file_path, encoding="utf-8")
                documents.extend(loader.load())
            else:
                print(f"N√£o foi poss√≠vel baixar o conte√∫do de {file['path']}")

        # Criar embeddings e vectorstore
        embeddings = OpenAIEmbeddings()
        vector_db = Chroma.from_documents(
            documents=documents, embedding=embeddings, persist_directory="./chroma_db"
        )

        return vector_db

    def search_with_tool(self, query):
        """Realiza uma busca sem√¢ntica usando a ferramenta GithubSearchTool"""
        return self.tool.run(query)

    def create_conversation_chain(self):
        try:
            # Configura√ß√£o da mem√≥ria
            memory = ConversationBufferMemory(
                memory_key="chat_history", return_messages=True, output_key="answer"
            )

            # Cria√ß√£o da cadeia
            conversation_chain = ConversationalRetrievalChain.from_llm(
                llm=self.llm,
                retriever=self.retriever,
                memory=memory,
                return_source_documents=True,
            )

            return conversation_chain
        except Exception as e:
            print(f"ERRO ao criar a chain de conversa√ß√£o: {str(e)}")
            print(f"Tipo de exce√ß√£o: {type(e).__name__}")
            import traceback

            traceback.print_exc()
            return None

    def _setup_retriever(self):
        """
        Configura e retorna o retriever para busca de informa√ß√µes relevantes.

        Este m√©todo verificar√° se a base de dados vetorial j√° foi inicializada.
        Se n√£o, retornar√° None e o retriever ser√° configurado posteriormente
        ap√≥s o carregamento dos dados do GitHub.

        Returns:
            Retriever ou None: Objeto retriever configurado para busca sem√¢ntica
        """
        # Se o vector_db ainda n√£o foi inicializado, retorna None
        # Ser√° configurado posteriormente ap√≥s load_github_data() ser chamado
        if self.vector_db is None:
            print(
                "Base de dados vetorial ainda n√£o inicializada. O retriever ser√° configurado ap√≥s o carregamento dos dados."
            )
            return None

        # Configurar o retriever a partir da base de dados vetorial
        try:
            # Criar o retriever com busca por similaridade
            retriever = self.vector_db.as_retriever(
                search_type="similarity",
                search_kwargs={
                    "k": 5,  # N√∫mero de documentos a serem recuperados
                    "fetch_k": 20,  # Busca inicial mais ampla
                    "score_threshold": 0.5,  # Limiar de pontua√ß√£o para relev√¢ncia
                },
            )

            print("Retriever configurado com sucesso.")
            return retriever

        except Exception as e:
            print(f"ERRO ao configurar o retriever: {str(e)}")
            import traceback

            traceback.print_exc()
            return None


def conversar_com_repo(repo_url):
    """
    Inicia uma conversa interativa sobre um reposit√≥rio GitHub

    Args:
        repo_url: URL do reposit√≥rio GitHub
    """
    print(f"ü§ñ Iniciando agente para o reposit√≥rio: {repo_url}")
    print("‚è≥ Carregando dados e criando base de conhecimento...")

    # Criar o agente com ID de sess√£o para persist√™ncia
    session_id = f"github_{repo_url.split('/')[-2]}_{repo_url.split('/')[-1]}"
    github_agent = GitHubRagTool(
        repo_url=repo_url, content_types=["code", "issue", "pr"], session_id=session_id
    )

    # Carregar dados do GitHub
    github_agent.load_github_data()

    print("\n‚úÖ Agente pronto! Voc√™ pode come√ßar a conversar sobre o reposit√≥rio.")
    print("üìù Digite 'sair' para encerrar a conversa\n")

    while True:
        user_input = input("üë§ Voc√™: ")

        if user_input.lower() in ["sair", "exit", "quit"]:
            print("\nüëã At√© a pr√≥xima!")
            break

        print("\n‚è≥ Processando...")
        result = github_agent.chat(user_input)

        print(f"\nü§ñ Agente: {result['response']}")

        # Se quiser mostrar as fontes separadamente, descomente:
        # if result['sources']:
        #     print("\nüìö Fontes:")
        #     for i, source in enumerate(result['sources'], 1):
        #         if source["type"] == "issue":
        #             print(f"  {i}. Issue #{source['number']}: {source['title']} - {source['url']}")
        #         elif source["type"] == "code":
        #             print(f"  {i}. Arquivo: {source['path']} - {source['url']}")


def main():
    # Exemplo de uso
    repo_url = input("Digite a URL do reposit√≥rio GitHub: ")

    # Verificar se √© uma URL v√°lida
    if "github.com" not in repo_url:
        print("URL inv√°lida. Use o formato: https://github.com/usuario/repositorio")
        return

    conversar_com_repo(repo_url)


if __name__ == "__main__":
    main()
